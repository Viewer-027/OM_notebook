## 阶段二模拟面试题

#### 1.脚本的执行方式

```bash
##方式一、脚本绝对路径、脚本相对路径（./）
[root@web1 ~]# ./abc.sh 
[root@web1 ~]# root/abc.sh 

##方式二、sh 脚本路径   ；source 脚本路径  ; . 脚本路径
[root@web1 ~]# sh ./abc.sh
[root@web1 ~]# source ./abc.sh
[root@web1 ~]# . abc.sh
```



#### 2.有哪几种循环方式，格式，退出循环的方式

```bash
##1）for 循环
for 变量名 in 值1 值2 值3  
do
   命令序列
done
##2)while 循环
while [ 条件测试 ]     #条件成功一直执行，无条件写 ：
do
   命令序列
done

##退出循环的方式
break #跳出当前循环体，执行循环体后面的语句
exit  #退出脚本
continue #跳过该循环体的本次循环，根据条件判断是否进入下一次循环
```



#### 3.有哪几种条件判断的方式

```bash
##if
if [ 条件测试1 ];then
	命令序列1
else if [ 条件测试2 ];then     
	命令序列2
else
	命令序列n
fi

##case
case $i in 
1)
  命令序列1;;
2)
  命令序列2;;
*)
  默认命令序列;;
esac
```



#### 4.掐头去尾的格式，以及其他做字符串截取的方式，区分$[]  ${}  $()的区别

```bash
##字符串掐头去尾：
1、从左向右，最短匹配删除：${变量名#*关键词}
2、从左向右，最长匹配删除：${变量名##*关键词}
3、从右向左，最短匹配删除：${变量名%关键词*}
3、从右向左，最长匹配删除：${变量名%%关键词*}

字符串截取的用法： ${变量名:起始位置:长度}
起始位置从0开始计数

##字符串替换的两种用法：
1、只替换第一个匹配结果：${变量名/old/new}
2、替换全部匹配结果：${变量名//old/new}

## $[]
与$(())相同，做数值计算

## ${}
做字符串的截取

## $()
与`` 相同，直接返回命令执行的结果作为字符串存储
```



#### 5.`shell`常见的变量的含义，如:$$ $? $*等等？

```bash
echo $0                   #脚本的名称
echo $1                   #第一个参数
echo $2                   #第二个参数
echo $*                   #所有参数
echo $#                   #所有参数的个数(参数有几个)
echo $$                   #执行脚本的进程号（或者说当前进程的进程号）
$?						  #用于判断上一条命令执行是否成功，成功为0,不成功为非0
```



#### 6.`sed`如实现删除，修改，插入等操作的指令和格式

```bash
sed [选项] '条件指令' 文件
##常用选项
-n 屏蔽默认输出，默认sed会输出读取文档的全部内容
-r 支持正则拓展
-i 修改源文件

##删除
sed '3,5d' user

##修改
sed 's/a/b/g' user

##插入
a：append 行后追加
i：insert 行前插入
c：替换，替换一行内容
sed '1a xx' user
sed '1i xx' user
```



#### 7.`grep` 常见的几个选项，如过滤空行，不区分大小写

```bash
##grep
-v  #去反
-i  #不区分大小写
-E  #启用正则拓展，等于egrep
-R  #递归目录
-n  #显示行号
-o 	#只输出匹配的内容
-c  #统计匹配到等行数

#过滤空行
grep -v ^$ 文件名
```



#### 8.几个基本的正则符号的使用

| ***\*正则符号\**** | ***\*描述\****                           |
| ------------------ | :--------------------------------------- |
| ^                  | 匹配行首                                 |
| $                  | 匹配行尾                                 |
| []                 | 集合，匹配集合中的任意单个字符           |
| [^]                | 对集合取反                               |
| .                  | 匹配任意单个字符                         |
| *                  | 匹配前一个字符任意次数 [*不允许单独使用] |
| \{n,m\}            | 匹配前一个字符n到m次                     |
| \{n\}              | 匹配前一个字符n次                        |
| \{n,\}             | 匹配前一个字符n次及以上                  |
| \(\)               | 组合为整体，保留                         |



#### 9.awk的选项和常见的几个带的变量，另外会默写统计日志文件ip出现次数的那段数组脚本

```bash
# awk的选项
-F  #指定分割符

# awk常用内置变量：
$0   文本当前行的全部内容
$1   文本的第1列
$2   文件的第2列
$3   文件的第3列，依此类推
NR   文件当前行的行号
NF   文件当前行的列数（有几列）

#
awk '{ip[$1]++}END{for(i in ip){print ip[i],i}}' log.txt | sort -nr 
#使用sort命令增加排序功能，-n是以数字形式排序，-r是降序
```



#### 10.什么是灰度发布

灰度发布是用比较平稳的方式升级或者替换产品项目的方法统称



#### 11.nginx如何实现调度器的功能

```bash
一、Nginx反向代理（七层代理）
#1）Nginx编译安装
#2）nginx配置文件
#使用upstream定义后端服务器集群，集群名称任意
#使用server定义集群中的具体服务器和端口
      upstream webserver {
         server 192.168.99.100:80;
         server 192.168.99.200:80;
        }
      server {
          listen       80;
          server_name  localhost;
          #charset koi8-r;
          #access_log  logs/host.access.log  main;
          location / {
              root   html;
              index  index.html index.htm;
              proxy_pass http://webserver;  #通过proxy_pass将用户的请求转发给webserver集群
          }

二、Nginx的TCP/UDP调度器（四层代理）
#1）Nginx编译安装时需要使用--with-stream，开启ngx_stream_core_module模块
#2）nginx配置文件
...
      stream {
        upstream backend {             #创建集群，名称为backend
            server 192.168.99.100:22;  #后端SSH服务器IP和端口
            server 192.168.99.200:22;
          }
         server {               #调用集群
            listen 12345;       #Nginx代理监听的端口，可以自己定义
            proxy_pass backend; #调用backend集群
          }
     }
http {
.. ..
}
```



#### 12.nginx有哪些优化

```bash
##优化Linux内核参数（最大文件数量）
[root@web1 ~]# ulimit -n          #查看最大文件数量
1024                    
[root@web1 ~]# ulimit -n 100000    #临时设置最大文件数量

##优化并发量
.. ..
   #user  nobody;
   worker_processes  2;     #与CPU核心数量一致
.. ..
   events {
       worker_connections  50000;
   }
.. ..
##优化数据包头缓存
.. ..
http {
    client_header_buffer_size    200k;    #添加，请求包头信息的缓存大小
    large_client_header_buffers  4 200k;  #添加，大请求包头部信息的缓存个数与容量
    include       mime.types;
    default_type  application/octet-stream;
.. ..
```



#### 13.ansible常见的模块有哪些，至少说出5个以上

```bash
shell、script、file、copy、user、group
```



#### 14.ansible如何定义变量

```bash
Ansible支持十几种变量定义方式

Ansible变量定义的位置，下列变量优先级从低到高
role defaults ：roles defaults目录下的变量
inventory vars：inventory文件中定义的变量
inventory group_vars：inventory文件组的变量
inventory host_vars：inventory文件主机的变量
playbook group_vars：剧本中组的变量
playbook host_vars：剧本中主机的变量
host facts：事实变量
play vars：vars定义的变量
play vars_prompt：vars_prompt定义的变量
play vars_files：vars_files导入的变量
registered vars：注册变量
role and include vars：roles中单独定义的及导入的变量
block vars (only for tasks in block)：block中定义的变量
task vars (only for the task)：任务中定义的变量
extra vars (always win precedence)：命令行指定的变量
```



#### 15.copy和template、fetch模块的区别

```bash
copy 用于将文件从控制节点复制到受控制节点
template  通过变量可以动态的复制文件到受控制节点
fetch  从受控节点获取文件到控制节点
```



#### 16.handler的使用场景,如何实现循环

```bash
#使用场景
#配置文件发生改变，需要重启服务
#循环实现，loop
loop:
    - alice
    - bob
    - charlie
----
loop:
    - ['alice', 'admin']
    - ['bob', 'developer']
    - ['charlie', 'guest']
```

#### 17.role角色创建后会出现哪些目录结构

```bash
roles/motd/
├── defaults
│   └── main.yml
├── files
├── handlers
│   └── main.yml
├── meta
│   └── main.yml
├── README.md
├── tasks
│   └── main.yml
├── templates
├── tests
│   ├── inventory
│   └── test.yml
└── vars
    └── main.yml
```

#### 18.ansible调用配置文件的优先级

- 首先检测ANSIBLE_CONFIG变量定义的配置文件

- 其次检查当前目录下的./ansible.cfg文件
- 再次检查当前用户家目录下的~/ansible.cfg文件
- 最后检查/etc/ansible/ansible.cfg文件





#### 19.lvs和nginx与haproxy调度器之间的区别

- LVS：因为 LVS 工作在内核态，并且主要负责四层的流量转发，所以它的性能非常高，能够处理非常大的流量负载。
- Nginx：虽然 Nginx 也能处理大量的请求，但是因为它需要解析应用层的信息，所以在处理复杂的七层逻辑时，性能会低于 LVS。
- HAProxy：HAProxy 在处理七层负载均衡时的性能优于 Nginx，尤其是在需要精细控制的情况下。对于四层负载均衡，其性能也很不错。

#### 20.ceph常见的组件有哪些

- 监视器：MON(Monitor)
  - Monitor负责管理Ceph集群的整体状态、配置信息和监控数据
  - 维护集群状态图和管理守护程序和客户端之间的身份验证
  - 它们定期选举一个Leader来协调集群中的其他节点，并接收和处理客户端和OSD的请求
  - 为了冗余和高可用性，通常至少需要三台Monitor
- 管理器：MGR(Manager)
  - Manager提供集群管理功能，包括集群状态监控、元数据管理、REST API接口等
  - 托管基于python的模块来管理和公开Ceph集群信息，包括基于web的Ceph仪表板和REST API
  - 以便管理员和用户可视化地管理和操作Ceph集群
  - 高可用性通常需要至少两台Manager
- OSD（Object Storage Daemon）
  - OSD是Ceph存储集群的核心组件
  - 负责存储数据和处理数据的复制、恢复和再平衡
  - 通过检查其他Ceph OSD守护进程的心跳来为Ceph监视器和管理器提供一些监视信息
  - 每个OSD节点都有一个或多个OSD进程来管理对应的存储设备
  - 为了实现冗余和高可用性，通常至少需要三个Ceph OSD
- MDS（Metadata Server）
  - MDS用于支持Ceph文件系统 (CephFS)
  - 负责维护文件系统的元数据
  - 回答客户端的访问请求，负责文件名到inode的映射，以及跟踪文件锁
- RGW（RADOS Gateway）
  - RGW是Ceph提供的对象存储网关，兼容S3和Swift协议
  - 它为用户提供了通过RESTful API与Ceph存储集群进行交互的能力



#### 21.zabbix监控模板的创建流程，做过哪些自定义监控的key值

```bash
[root@web1 ~]# vim /etc/zabbix/zabbix_agentd.d/usercnt.conf
UserParameter=usercnt,sed -n '$=' /etc/passwd
[root@web1 ~]# systemctl restart zabbix-agent.service 
```



#### 22.zabbix主动监控和被动监控的区别

- 默认zabbix使用的是被动监控，主被动监控都是针对被监控主机而言的。
- 被动监控：Server向Agent发起请求，索取监控数据。此种模式常用
- 主动监控：Agent向Server发起连接，向Server汇报



#### 23.prometheus监控的流程

```ABAP
第一步: Prometheus server定期从配置好的jobs 或者 exporters ，或者从Pushgateway，或者从其他的 Prometheus server 中拉metrics。

默认使用的拉取方式是pull，也可以使用pushgateway提供的push方式获取各个监控节点的数据。

第二步: Prometheus server在本地存储收集到的 metrics，并运行已定义好的alert.rules，通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。记录新的时间序列或者向Alertmanager推送警报。

获取到的数据存入TSDB，一款时序型数据库。

第三步: Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，

例如Grafana、自带的Promdash以及自身提供的模版引擎等等。
Prometheus还提供HTTPAPI的查询方式，自定义所需要的输出。
```



#### 24.keepalive的工作原理

其工作原理是通过VRRP协议实现主备节点之间的状态同步，当主节点出现故障时，备节点会接管主节点的VIP地址，从而实现服务的高可用性。

VRRP是虚拟路由器冗余协议（Virtual Router Redundancy Protocol）的缩写，是一种实现路由器冗余的协议。VRRP协议可以将多台路由器组成一个虚拟路由器，这个虚拟路由器有一个虚拟IP地址，可以提供给客户端使用。在这个虚拟路由器中，只有一台路由器是活动的，其他路由器都是备份的。当活动路由器出现故障时，备份路由器会接管虚拟IP地址，从而实现路由器的高可用性。



#### 25.iptables如何防止别人访问我的80端口服务，写成语句

```bash
# 拒绝所有外部 IP 对 80 端口的访问
iptables -A INPUT -p tcp --dport 80 -j DROP
# 或者，明确拒绝（返回拒绝消息）
iptables -A INPUT -p tcp --dport 80 -j REJECT
```



#### 26.如何抓取本机的eth0网卡的访问web服务的情况

```bash
# 抓取 eth0 网卡上访问 HTTP 服务（80 端口）的数据包
sudo tcpdump -i eth0 port 80
# 抓取 eth0 网卡上访问 HTTPS 服务（443 端口）的数据包
sudo tcpdump -i eth0 port 443
# 同时抓取 HTTP 和 HTTPS 服务的数据包
sudo tcpdump -i eth0 port 80 or port 443
```



## 阶段三模拟面试



#### 数据库主从搭建的过程 

```bash
主库设置：
启用binlog日志、设置server_id
授予用户查看binlog日志的权限
查看主库状态信息（日志名、偏移量）#show master status

从库设置:
设置server_id
指定主库信息  #change master to
启动slave进程  #start slave
查看从库状态信息 #show slave status

```

#### 数据库主从同步的原理 

```bash
主库将数据的事务操作（DML）记录binlog日志文件中

从库监听到binlog日志变化时，IO线程去将主库的binlog日志变化写入到relaylog中，主库产生log dump线程，binlog日志内容传输个从库; 从库的SQL线程将relaylog文件中的更新执行一遍，达到了与主库数据一致的目的

```

#### 数据库的字段类型有哪些 

```
字符型
char varchar text blob enum set

数值型
intyint smallint mediumint int bigint 
float double
decimal

日期和实际类型
date time year datetime timestamp

布尔型
bool boolean
```



#### sql语句中增删改查的具体语法

```sql
SELECT * FROM employees;

INSERT INTO employees (first_name, last_name, department)
VALUES ('John', 'Doe', 'HR');

UPDATE employees
SET department = 'Finance'
WHERE employee_id = 102;

DELETE FROM employees
WHERE last_name = 'Doe';

```



#### 数据库备份的方式有哪些，相关命令 

```bash
冷备份(完全关闭)：    cp -r /var/lib/mysql  /mysql.bak

温备份(只读)：  mysqldump --sintrabackupgle-transaction --lock-tables=false -u username -p database_name > backup.sql

热备份(正常)： xtrabackup --host=127.0.0.1 --user=用户名  --password=密码 --backup --target-dir=备份目录 --datadir=数据库目录
```



#### 多表连接有哪些连接方式，左连接和右连接区别 

```bash
1. 内连接（INNER JOIN）
只返回两个表中满足连接条件的记录。
2. 左连接（LEFT JOIN 或 LEFT OUTER JOIN）
返回左表中的所有记录，以及右表中满足连接条件的记录；对于左表中有但右表中无对应记录的情况，结果集中右表的字段将填充为 NULL。
3. 右连接（RIGHT JOIN 或 RIGHT OUTER JOIN）
返回右表中的所有记录，以及左表中满足连接条件的记录；对于右表中有但左表中无对应记录的情况，结果集中左表的字段将填充为 NULL。
4. 全外连接（FULL JOIN 或 FULL OUTER JOIN）
返回两个表中的所有记录，对于不满足连接条件的记录，相应表中的字段将填充为 NULL

```



#### redis持久化的方式有哪些，对比一下优缺点 

```bash
RDB
将数据集快照写入磁盘，文件名默认dump.rdb
优点：性能高效，文件比AOF小，只保存某个时间点的数据状态、易于备份
缺点：
数据有丢失风险
频繁fork操作，对大数据库来说，消耗较多资源

AOF
记录服务器接收到的每一个写操作，在 Redis 重启时会重新执行这些命令来恢复数据。
优点：更好的数据安全性、
缺点：
AOF 文件会变得越来越大、可能占用更多存储空间
AOF 需要逐条执行日志文件中的命令来重建数据集，恢复时间较长
```



#### 怎么判断主从是否有延时，造成延时的原因有哪些 

```bash
info replication  #查看复制状态信息

master_last_io_seconds_ago  #上次与主服务器交互的时间（秒），理想情况下应接近0。
slave_repl_offset  #当前从节点处理到的偏移量，如果这个值比主节点的 master_repl_offset 小很多，则表明存在延迟。
lag  #从节点与主节点之间的延迟时间（秒）。

原因
网络延迟
主、从节点负载过高
大批量数据同步发生
AOF持久化操作影响
```



#### redis哨兵服务作用是什么 

```bash
Redis 官方提供的高可用性解决方案
持续监控master服务器
当master宕机时，将slave升级为master服务器
```



#### sql语句中常见的函数有哪些，分组 排序的关键词是什么 

```
字符函数

数字函数

日期函数

聚合函数



order by 。。。。 limit。。。。。
```



#### 主从之间不同步了怎么恢复 

```bash
INFO replication #查看复制信息

重启从节点

从新配置从库
```

#### 数据库做过哪些优化

```bash
1. 索引优化
对频繁查询的字段添加合适的索引，比如在 WHERE 和 JOIN 条件中常用的列上创建单列或复合索引。
避免过度索引，定期分析和清理无效或重复的索引，以减少写入开销。
使用 EXPLAIN 分析 SQL 执行计划，确保查询命中了正确的索引。

2. SQL 查询优化
避免使用 SELECT *，只选择必要的字段。
减少子查询嵌套，改用 JOIN 操作提高效率。
对大数据量表进行分页优化，避免使用 LIMIT offset, size 造成性能下降。

3. 数据库配置调优
调整连接池大小、最大连接数等参数，防止连接资源耗尽。
根据服务器配置调整缓冲池（如 MySQL 的 InnoDB Buffer Pool）大小，提升数据读取效率。
合理设置日志刷新策略（如 redo log、binlog），平衡性能与数据安全。

4. 表结构与分区设计
对大表进行水平分表或按时间分区，提升查询效率。
适当进行反规范化处理，减少多表关联带来的性能损耗。

5. 主从复制与读写分离
利用主从架构分散读压力，将读操作路由到从库，减轻主库负担。

6. 监控与慢查询分析
开启慢查询日志，定期分析并优化执行时间较长的 SQL。
使用监控工具（如 Prometheus + Grafana 或 MySQL 自带的性能模式）实时掌握数据库运行状态。
```

#### 什么是redis的雪崩 

```bash
在某一时间同时有大量的key失效，导致大量的请求直接来到数据库，数据库压力过大导致崩溃
```



#### 数据库的储存引擎，说明MyISAM与InnoDB的区别 

```bash
首先，InnoDB 支持事务处理，而 MyISAM 不支持事务。这意味着如果我们的业务涉及到像支付、订单这样的高一致性需求，就需要使用 InnoDB 来保证数据的完整性和回滚能力。

其次，在锁机制方面，InnoDB 支持行级锁，而 MyISAM 使用的是表级锁。这也就意味着，在并发访问较高的情况下，InnoDB 能提供更好的并发性能，因为只锁定当前操作的行，而不是整张表。

第三点是关于外键约束。InnoDB 支持外键，可以用来维护表之间的关联关系，而 MyISAM 不支持外键。所以在需要强关联约束的数据模型中，通常会选择 InnoDB。

另外，在崩溃恢复方面，InnoDB 具备自动恢复的能力，可靠性更高；而 MyISAM 在数据库崩溃后需要手动修复，安全性相对较低。

最后在使用场景上，MyISAM 更适合以读为主的场景，比如静态数据、缓存表等；而 InnoDB 更适合需要高并发、事务支持和数据一致性的场景，例如金融系统或电商平台的核心业务表。

总的来说，现在大多数项目默认都会使用 InnoDB，因为它功能更全面，尤其是在对数据安全性和并发性要求更高的场景下。
```





#### 主键 外键 索引 事务 这些数据库约束关系的作用

```bash
主键：唯一标识表中的记录，一个表只能有一个主键
外键：表的外键，代表另一个表中的主键，定义两表之间的关系
```

#### 数据库主从复制的模式有哪些

```bash
1. 异步复制（Asynchronous Replication）
描述：在异步复制模式下，主库执行完写操作后立即响应客户端，而不会等待从库确认是否已成功接收并应用了这些更改。
优点：
性能较高，因为主库无需等待从库的响应。
缺点：
可能导致主从之间的数据延迟，尤其是在网络条件不佳或负载较高的情况下。
如果主库发生故障，最新写入的数据可能尚未同步到从库，造成数据丢失。
2. 半同步复制（Semi-Synchronous Replication）
描述：介于全异步和全同步之间的一种模式。主库在提交事务之前至少需要等待一个从库确认已经接收到该事务的日志信息，但不需要等到从库实际完成日志的应用。
优点：
提供了一定程度的数据安全性，减少了数据丢失的风险。
缺点：
相比异步复制，可能会有轻微的性能下降，因为主库需要等待至少一个从库的确认。
3. 全同步复制（Fully Synchronous Replication）
描述：在全同步复制模式下，主库必须等到所有从库都确认已经接收到并且成功应用了事务之后才会向客户端返回成功的响应。
优点：
数据一致性最高，几乎可以完全避免数据丢失。
缺点：
性能较差，特别是在从库数量较多或者网络延迟较大的情况下，会影响系统的响应速度。
4. 级联复制（Cascading Replication）
描述：在这种模式下，不是所有的从库直接连接到主库，而是某些从库作为中间节点（即二级主库），其他从库再从这些中间节点进行复制。
优点：
减轻了主库的压力，适合大规模部署环境。
缺点：
增加了系统复杂性，并且如果某个中间节点出现问题，可能会影响到其下游的所有从库。
5. 多源复制（Multi-source Replication）
描述：允许一个从库同时从多个主库复制数据。这种模式特别适用于需要整合来自多个数据库的数据的情况。
优点：
能够实现跨数据库的数据集成。
缺点：
复杂度较高，配置和维护难度大。
6. 延迟复制（Delayed Replication）
描述：故意设置一定的延迟时间，在这段时间内，从库不会立即应用来自主库的更改。这有助于在意外删除或错误更新的情况下保留一段时间内的旧数据版本。
优点：
提供了一种简单的方法来恢复最近的历史数据。
缺点：
显著增加了数据不一致的时间窗口。
```

#### git的操作指令有哪些

```bash
1. 配置相关
git config --global user.name "Your Name"：设置全局用户名。
git config --global user.email "your.email@example.com"：设置全局用户邮箱。
git config --list：列出所有配置项。
2. 仓库操作
git init：初始化一个新的 Git 仓库。
git clone <repo_url>：从远程仓库克隆项目到本地。
git remote add origin <repo_url>：添加远程仓库地址。
git remote -v：查看当前配置的远程仓库地址。
3. 提交更改
git status：查看工作目录的状态（哪些文件被修改、哪些文件未跟踪）。
git add <file_name> 或 git add .：将更改添加到暂存区（前者指定文件，后者添加所有更改）。
git commit -m "commit message"：提交暂存区的更改，并附上提交信息。
git commit --amend：编辑最后一次提交（可用于修改提交信息或追加更改）。
4. 分支管理
git branch：列出所有本地分支，并标记当前所在分支。
git branch <branch_name>：创建新分支。
git checkout <branch_name>：切换到指定分支。
git checkout -b <branch_name>：创建并切换到新分支。
git merge <branch_name>：将指定分支合并到当前分支。
git branch -d <branch_name>：删除已合并的分支。
git push origin --delete <branch_name>：删除远程分支。
5. 与远程交互
git fetch：从远程获取最新更新但不自动合并。
git pull：从远程拉取最新更改并尝试自动合并到当前分支。
git push：将本地提交推送到远程仓库。
6. 查看历史记录
git log：显示提交历史。
git log --oneline：以简洁的一行格式显示提交历史。
git diff：显示尚未暂存的文件差异。
git show <commit_id>：查看特定提交的详细信息和更改内容。
7. 撤销操作
git reset <file>：取消暂存指定文件。
git reset --hard HEAD：放弃所有未提交的更改，恢复工作目录至最近一次提交的状态。
git revert <commit_id>：创建一个新的提交来撤销指定提交的更改。
```

#### cicd的工作流程是怎样的 

```bash
持续集成（CI）和持续交付/部署（CD）

比如我们平时写完代码之后，会把代码提交到 Git 上，比如 GitHub 或者 GitLab。这个时候，就可以触发一个叫 CI（持续集成）的过程。

CI 会自动拉取最新的代码，然后做一些事情，比如安装依赖、编译项目、跑单元测试这些。如果这一步出错了，它就会马上告诉我们哪里有问题，不能合并或者上线。

等 CI 成功完成后，接下来就是 CD 阶段了。CD 一般有两种情况，一个是 持续交付（Continuous Delivery），一个是 持续部署（Continuous Deployment）。

如果是交付的话，它会把程序打包好，可能部署到测试环境或者预发布环境，等着人工审核通过后再决定要不要上线。
如果是部署的话，那就是完全自动化的，只要测试都通过了，就直接部署到生产环境。
在整个过程中，通常还会结合一些工具，比如 Jenkins、GitLab CI、GitHub Actions 做流水线，再配合 Docker 和 Kubernetes 来做容器化部署。

最后上线以后，也会有监控系统去观察服务运行是否正常，出了问题也能快速回滚。

总的来说，CI/CD 就是为了让我们更快、更安全地把代码从开发阶段顺利推进到生产环境，同时减少人为操作的错误。
```

































## Anisble问答题

#### Ansible 的核心组件主要包括：

- Inventory：定义了你要管理的主机或主机组。
- Playbooks：YAML格式的文件，描述了你希望在远程机器上执行的任务。
- Modules：是实际工作的单元，可以被命令或playbook调用以完成特定任务。
- Plugins：扩展Ansible的功能，包括连接、查找、过滤等不同类型。
- APIs：允许Ansible与其他工具集成。

#### Ad-hoc与Playbook模式的区别

- Ad-hoc: 用于快速执行单一命令，适用于临时性操作。例如，检查所有服务器的时间设置可以用一条命令完成。
- Playbook: 更结构化和持久化的配置管理方式，适合复杂场景，由一系列按顺序执行的任务组成，可重复使用。

#### 在Ansible中使用变量

可以通过多种方式定义变量，如在Inventory文件、Playbook内、外部变量文件中定义，或者通过命令行传递。在任务中引用变量时使用 {{ variable_name }}。

#### 处理敏感数据

利用Ansible Vault加密文件或变量中的敏感信息。只有拥有正确密码的人才能查看或修改这些内容。

#### 调试Ansible Playbook

使用 -vvv 参数增加输出详细程度，或者使用内置的debug模块打印变量值来帮助调试。

#### Ansible Roles的作用

Roles提供了一种组织Playbook的方式，使得它们更易于重用和理解。一个Role包含了一系列预定义的目录结构，用于存放tasks、handlers、vars等。

#### 创建一个Role

使用ansible-galaxy init role_name命令创建基本框架。
根据需求填充tasks、handlers、vars等内容。
在Playbook中引用该Role。

#### 处理任务失败

默认情况下，Ansible会在任务失败时停止执行。可以通过ignore_errors: yes忽略错误继续执行后续任务，或者使用块（blocks）进行错误处理。

#### 优化执行性能

使用async和poll异步执行长时间运行的任务。
减少不必要的facts收集。
使用本地连接类型执行无需SSH的任务。

#### 动态生成Inventory

编写脚本或使用动态Inventory插件从CMDB或其他来源获取主机列表。

#### Ansible与Puppet、Chef的区别

- Ansible: 基于SSH，不需要客户端代理；语法简单易懂（YAML）。
- Puppet: 需要客户端代理；基于声明式语言，更适合大型环境。
- Chef: 也需要客户端代理；采用Ruby编写Cookbooks，灵活性高。

#### 使用条件判断

通过when语句根据变量值、facts等条件决定是否执行某任务。

#### 管理版本

可以通过Python包管理器pip安装不同版本，或使用像pyenv这样的工具管理多个版本。

#### 扩展功能

开发自定义模块、插件或利用Ansible Galaxy共享社区贡献的内容。

#### 识别不同的系统

通过Gathered Facts（自动收集的信息）了解目标系统的详情，比如操作系统类型、版本等，从而编写适应性强的Playbooks。





## Prometheus的监控流程

#### 描述一下prometheus的监控架构







#### Prometheus有哪些常用的exporter？

Prometheus支持多种exporter，以下是一些常用的exporter：

这些exporter可以通过配置文件将其与Prometheus集成，从而实现对各种系统和服务的监控。



#### Prometheus为什么会用到Grafana？

Prometheus本身是一个指标收集和存储的工具，虽然它提供了一个强大的查询语言PromQL，但是它的可视化和报表功能相对较弱。因此，为了更好地展示和分析Prometheus收集的指标数据，通常会使用Grafana进行可视化和报表。

Grafana是一个强大的数据可视化和监控分析平台，支持从多种数据源中查询和展示指标数据，其中就包括Prometheus。Grafana提供了一个直观的Web界面，使用户能够轻松地创建和共享仪表板，并对数据进行分析和警报。Grafana支持多种面板类型，如图形面板、仪表板、表格面板等，可以用于展示各种指标数据。

因此，使用Grafana可以更好地展示和分析Prometheus收集的指标数据，提高监控和分析的效率和可视化程度。Grafana可以与Prometheus集成，从而实现对各种系统和服务的监控和分析。

#### Prometheus有哪些自动发现的方式？

Prometheus支持多种自动发现的方式，以下是一些常用的方式：

File-based服务发现：Prometheus可以通过读取文件的方式自动发现服务实例，并收集它们的指标数据。

Kubernetes服务发现：Prometheus可以通过Kubernetes API自动发现Kubernetes集群中的服务和Pod，从而收集它们的指标数据。

Consul服务发现：Prometheus可以通过Consul API自动发现Consul中的服务实例，并收集它们的指标数据。

DNS服务发现：Prometheus可以通过DNS解析自动发现服务实例，并收集它们的指标数据。



#### 通过Alertmanager配置告警和通知的主要步骤有哪些？

通过Alertmanager配置告警和通知的主要步骤如下：

配置Prometheus告警规则：在Prometheus的配置文件中，定义告警规则

配置Alertmanager接收器：在Alertmanager的配置文件中，定义接收器

配置Alertmanager路由器：在Alertmanager的配置文件中，定义路由器

启动Prometheus和Alertmanager：启动Prometheus和Alertmanager，让它们读取配置文件并运行

测试告警和通知：通过满足告警条件，触发告警并发送通知，验证告警和通知是否正常工作





















## iptables问答题

#### 1.iptables有几张表，作用是什么

- filter：主要用于过滤和控制流入和流出的数据包
- nat：用于修改数据包的源地址或目标地址，实现地址转换
- mangle：提供了更细粒度的控制，可以修改数据包的各种属性
- raw：用于优化性能，通过绕过连接跟踪机制来降低开销

#### 2.iptables有几种链，作用是什么

- PREROUTING：在进行路由决策前，处理进入的数据包，通常用于修改目标地址（DNAT），例如端口转发
- INPUT：处理目的地为本机的数据包，在路由之后，决定哪些数据包允许进入主机
- FORWARD：处理通过本机但目的地不是本机的数据包，用于决定哪些数据包可以通过本机从一个网络接口转发到另一个网络接口。
- OUTPUT: 处理从本机出发的数据包，在路由决策后。用于决定哪些数据包可以从本机发送出去。
- POSTROUTING：处理即将离开的数据包，在路由决策之后。通常由于修改源地址（SNAT），例如IP伪装。

#### 3 .iptables的规则链默认规则都有什么，如何设置？

```bash
# 默认规则有ACCEPT、DROP、REJECT
-P设置，例如
iptables -P INPUT DROP
```



#### 4.什么是NAT，为什么需要NAT技术？

NAT（Network Address Translation）是一种将私有（保留）地址转化为合法IP地址的转换技术。NAT可以将IP数据报文头中的IP地址转换为另一个IP地址，并通过转换端口号达到地址重用的目的。NAT作为一种缓解IPv4公网地址枯竭的过渡技术，由于实现简单，得到了广泛应用。NAT的工作机制是网络访问只能先由私网侧发起，公网无法主动访问私网主机。NAT路由器在两个访问方向上完成两次地址的转换或翻译，出方向做源信息替换，入方向做目的信息替换；NAT路由器的存在对通信双方是保持透明的；NAT路由器为了实现双向翻译的功能，需要维护一张关联表，把会话的信息保存下来。

NAT技术的主要作用是解决IPv4地址短缺的问题。在互联网普及之初，IP地址并不是如今这样稀缺的资源，但是随着互联网的飞速发展，IPv4地址快速枯竭，而IPv6的普及又存在一定的难度。为了解决IPv4地址的短缺问题，NAT技术得到了广泛的应用。此外，NAT技术还能够有效地避免来自网络外部的攻击，隐藏并保护网络内部的计算机。

#### 5.什么是私有地址？私有地址有哪些？

私有地址是指在私有网络中使用的IP地址，这些地址在公共互联网中是不可路由的。私有地址的使用可以有效地解决IP地址的短缺问题，同时也增加了网络的安全性。

私有地址的范围在IPv4中是10.0.0.0/8、172.16.0.0/12和192.168.0.0/16，而在IPv6中则是fc00::/7。



#### 6.什么是SNAT？

SNAT（Source Network Address Translation）是指将源IP地址进行转换的技术。在使用SNAT时，源IP地址会被替换为一个新的IP地址，这个新的IP地址通常是路由器的IP地址或是一个公网IP地址。SNAT通常用于将私有网络内部的主机与公共互联网进行通信，以达到隐藏内部网络拓扑结构的目的。















